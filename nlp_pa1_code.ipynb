{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y95pMh2nkwzE"
      },
      "source": [
        "### 1. Installation Library & Download Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KK47qdrUagva",
        "outputId": "d3e6946c-d701-480f-a6e9-3073ba9d94d6"
      },
      "outputs": [],
      "source": [
        "# Install required NLP libraries\n",
        "!pip install nltk textblob spacy\n",
        "# Download the small English model for spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import nltk\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxdBkiTpkmx2"
      },
      "source": [
        "### 2. Data Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t3af3Ybksb7",
        "outputId": "e2443936-bba1-487f-bd4b-63c1edefbb26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Print the current working directory\n",
        "print(os.getcwd())\n",
        "# List all files in the current directory\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo0bYeHHkigO"
      },
      "source": [
        "### 3. Read text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGXfSPm1czGt"
      },
      "outputs": [],
      "source": [
        "# Read the input text file (alice29.txt)\n",
        "with open('alice29.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8VBbr30kgnd"
      },
      "source": [
        "### 4. Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFMforxndz0-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Convert all characters to lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Preserve whitespace (\\s), remove only non-alphabetic characters\n",
        "text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "\n",
        "# Merge multiple spaces / line breaks into a single space\n",
        "text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Save cleaned text\n",
        "with open('cleaned.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GUGNP4ikc_K"
      },
      "source": [
        "### 5. NLTK Tokenization + Top10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgMR9uexd_Ad",
        "outputId": "4f831478-af70-4b1b-9d65-d8148ca3c8f0"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "# Load English stopwords from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenize the cleaned text into individual words\n",
        "words = word_tokenize(text)\n",
        "# Remove stopwords from the token list\n",
        "words = [w for w in words if w not in stop_words]\n",
        "\n",
        "# Save all remaining tokens to a file (one word per line)\n",
        "with open('words.txt', 'w') as f:\n",
        "    for w in words:\n",
        "        f.write(w + '\\n')\n",
        "\n",
        "# Count word frequencies\n",
        "freq = Counter(words)\n",
        "# Extract the top 10 most frequent words\n",
        "top10 = freq.most_common(10)\n",
        "\n",
        "# Save the Top-10 words and their frequencies\n",
        "with open('top10words.txt', 'w') as f:\n",
        "    for w, c in top10:\n",
        "        f.write(f\"{w}: {c}\\n\")\n",
        "# Display the Top-10 words in the notebook output\n",
        "top10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eYyQKKklNFX"
      },
      "source": [
        "### 6. Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoVKn1PIePnI",
        "outputId": "e919e898-a954-44f7-ddbc-65150cd80bf0"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import statistics\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Number of times each tokenizer is benchmarked\n",
        "RUNS = 10\n",
        "\n",
        "# Tokenization using NLTK\n",
        "def nltk_tok():\n",
        "    word_tokenize(text)\n",
        "\n",
        "# Tokenization using TextBlob\n",
        "def tb_tok():\n",
        "    TextBlob(text).words\n",
        "\n",
        "# Tokenization using spaCy\n",
        "def spacy_tok():\n",
        "    nlp(text)\n",
        "\n",
        "# Benchmark function to measure execution time\n",
        "def bench(fn):\n",
        "    \"\"\"\n",
        "    Measure the mean and standard deviation of execution time\n",
        "    for a given tokenization function.\n",
        "    \"\"\"\n",
        "    t = timeit.repeat(fn, number=1, repeat=RUNS)\n",
        "    return statistics.mean(t), statistics.stdev(t)\n",
        "\n",
        "# Run benchmarks for each framework\n",
        "results = {\n",
        "    'NLTK': bench(nltk_tok),\n",
        "    'TextBlob': bench(tb_tok),\n",
        "    'spaCy': bench(spacy_tok)\n",
        "}\n",
        "\n",
        "# Save performance comparison results to file\n",
        "with open('time_compares.txt', 'w') as f:\n",
        "    f.write(\"Framework\\tMean(s)\\tStd(s)\\n\")\n",
        "    for k, (m, s) in results.items():\n",
        "        f.write(f\"{k}\\t{m:.4f}\\t{s:.4f}\\n\")\n",
        "\n",
        "# Display benchmark results\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
